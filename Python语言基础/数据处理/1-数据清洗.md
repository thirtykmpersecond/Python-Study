# 重复值处理
Pandas去重步骤如下：
1. 利用`DataFrame`中`duplicated`方法返回一个`布尔型Series`，显示是否有重复行，没有重复的行显示为`FALSE`，有重复的行则从第二行起均显示为`True`
2. 利用`DataFrame`中`drop_duplicates()`返回一个除了重复行的DataFrame
```python
#duplicated(self, subset=None, keep='first')
from pandas import DataFrame
from pandas import Series
df = DataFrame({'age':Series([26,85,64,85,85]),
                'name':Series(['Ben','John','Jerry','John','John'])})
print(df)
#去重
print(df.duplicated())
print(df.duplicated('name'))
print(df.drop_duplicates('age'))
```
其中：
1. subset用于识别重复的列表签或列标签序列，默认所有列表签
2. keep='first'表示除第一次出现外，其余相同的数据被标记为重复
3. keep='last'表示除最后一次出现外，其余相同的数据被标记为重复
4. keep=False表示所有相同的数据都被标记为重复
5. **如果`duplicated`和`drop_duplicates`方法中没有设置参数，则默认判断全部列，**
6. **如果在这两个方法中加入了指定的属性名（或称为列名），例如`frame.drop_duplicates(['state'])`,则指定部分列（state列）进行重复项的判断。**

# 缺失值处理
从统计上看，缺失数据可能会产生有偏估计，从而使样本数据不能很好地代表总体。一般来说缺失值处理包括两个步骤：
**缺失数据的识别**和**缺失数据的处理**
## 缺失数据的识别
Pandas使用浮点值`NaN`表示符点和非符点数组里的缺失数据并使用`.isnull`和`.notnull`函数来判断缺失状况。
```python
from pandas import DataFrame
from pandas import read_excel

df = read_excel(r'~/Desktop/Python数据及相关的资料.nosync/rz.xlsx',sheet_name='Sheet2')
print(df)
#1.缺失数据识别
print(df.isnull())
print(df.notnull())
```
## 缺失数据的处理
1. 数据补齐
2. 删除对应行
3. 不处理
### dropna()去除数据结构中值为空的数据行
```python
newDF = df.dropna(how = 'all',axis = 1)
print(newDF)
newDF = df.dropna()
print((newDF))
```
+ `how='all'`指只有行/列里数据全部为空时丢弃
+ `axis=1`表示按列丢弃，默认为0，按行
### fillna()填充缺失值
```python
#用字符替代
print(df.fillna('?'))
#用前一个数值替代缺失值
print(df.fillna(method='pad'))
#用后一个数值替代缺失值，可以用limit限制每列可以替代NaN的数目
print(df.fillna(method='bfill'))
#为不同列填充不同的值来填补数据
print(df.fillna({'数分':100,'高代':0}))

#清除字符串左、右或首、尾指定的字符
df = DataFrame({'age':Series([26,85,64,85,85]),
                'name':Series(['Ben','John','Jerry','John','John'])})
#默认为空格，中间的不清除
print(df['name'].str.strip('J'))
#删除左/右
print(df['name'].str.lstrip('B'))
print(df['name'].str.rstrip('n'))
```
